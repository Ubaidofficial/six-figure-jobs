name: Daily Job Scraper (Automated)

on:
  schedule:
    - cron: '0 6,18 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'

    steps:
      - name: Trigger Railway Scraper API
        run: |
          echo "üöÄ Triggering job scraper on Railway..."

          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
            https://www.6figjobs.com/api/cron/scrape \
            -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
            -H "Content-Type: application/json" \
            --max-time 600 \
            --retry 2 \
            --retry-delay 30)

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | head -n-1)

          echo "üìä Response Code: $HTTP_CODE"
          echo "üìÑ Response Body: $BODY"

          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "‚úÖ Scraper triggered successfully"
            exit 0
          else
            echo "‚ùå Scraper failed with code $HTTP_CODE"
            exit 1
          fi

      - name: Report Failure
        if: failure()
        run: |
          echo "‚ö†Ô∏è Scraper failed!"
          echo "üîç Check Railway logs: https://railway.app/project/your-project/deployments"
