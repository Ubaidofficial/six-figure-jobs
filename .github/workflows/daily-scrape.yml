name: Daily Job Scraper (Automated)

on:
  schedule:
    - cron: "0 6,18 * * *" # 6am and 6pm UTC daily
  workflow_dispatch:

concurrency:
  group: daily-scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90 # Changed from 15 to 90 for full scrape

    if: github.event_name == 'schedule' || github.ref == 'refs/heads/develop'

    steps:
      - name: Trigger Railway Scraper API
        id: start
        shell: bash
        run: |
          set -euo pipefail

          echo "üöÄ Triggering job scraper on Railway..."
          echo "Event: $GITHUB_EVENT_NAME"
          echo "Ref:   $GITHUB_REF"

          RESPONSE=$(curl -sS -w "\n%{http_code}" -X POST \
            "https://www.6figjobs.com/api/cron/scrape?mode=all" \
            -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
            -H "Content-Type: application/json" \
            --retry 2 \
            --retry-delay 30)

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | head -n-1)

          echo "üìä Response Code: $HTTP_CODE"
          echo "üìÑ Response Body: $BODY"

          if [ "$HTTP_CODE" -lt 200 ] || [ "$HTTP_CODE" -ge 300 ]; then
            echo "‚ùå Scraper trigger failed with code $HTTP_CODE"
            exit 1
          fi

          # Parse success flags defensively (do not fail the step if BODY isn't valid JSON)
          SUCCESS="$(echo "$BODY" | jq -r '.success // .ok // false' 2>/dev/null || true)"
          JOB_ID="$(echo "$BODY" | jq -r '.jobId // .runId // empty' 2>/dev/null || true)"

          # If the API returns an explicit success=false, fail.
          # If there's no success flag, we still allow success if a jobId/runId exists.
          if [ "$SUCCESS" != "true" ] && [ -z "${JOB_ID:-}" ]; then
            echo "‚ùå Trigger response did not indicate success and no jobId was provided."
            exit 1
          fi

          echo "job_id=${JOB_ID:-}" >> "$GITHUB_OUTPUT"

          if [ -z "${JOB_ID:-}" ]; then
            echo "‚ö†Ô∏è Trigger succeeded but no jobId returned; continuing in fire-and-forget mode (skipping wait)."
            exit 0
          fi

          echo "‚úÖ Scraper started. jobId=$JOB_ID"

      - name: Wait for completion
        if: steps.start.outputs.job_id != ''
        shell: bash
        env:
          JOB_ID: ${{ steps.start.outputs.job_id }}
        run: |
          set -euo pipefail

          echo "‚è≥ Waiting for scrape completion. jobId=$JOB_ID"

          # 90 minutes max (540 * 10s)
          for i in $(seq 1 540); do
            RESPONSE=$(curl -sS -w "\n%{http_code}" \
              "https://www.6figjobs.com/api/scrape/status/$JOB_ID" \
              -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}")
            HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
            BODY=$(echo "$RESPONSE" | head -n-1)

            if [ "$HTTP_CODE" -eq 404 ]; then
              echo "‚ùå Status not found (jobId=$JOB_ID). The status store is in-memory; server restarts will lose it."
              exit 1
            fi

            STATE=$(echo "$BODY" | jq -r '.status // empty' 2>/dev/null || true)

            if [ "$STATE" = "completed" ]; then
              echo "‚úÖ Completed"
              echo "$BODY" | jq . || true
              exit 0
            fi

            if [ "$STATE" = "failed" ]; then
              echo "‚ùå Failed"
              echo "$BODY" | jq . || true
              exit 1
            fi

            echo "‚Ä¶ $i/540 status=$STATE"
            sleep 10
          done

          echo "‚ùå Timed out waiting for completion"
          exit 1

      - name: Report Failure
        if: failure()
        run: |
          echo "‚ö†Ô∏è Scraper failed!"
          echo "üîç Check Railway logs in your Railway project Deployments tab."
