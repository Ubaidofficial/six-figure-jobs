name: Daily Job Scraper

on:
  schedule:
    - cron: '0 6,18 * * *'  # 6 AM and 6 PM UTC (twice daily)
  workflow_dispatch:  # Manual trigger button in GitHub UI

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Trigger Railway Scraper API
        run: |
          echo "üöÄ Triggering job scraper on Railway..."
          
          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
            https://www.6figjobs.com/api/cron/scrape \
            -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
            -H "Content-Type: application/json" \
            --max-time 600 \
            --retry 2 \
            --retry-delay 30)
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | head -n-1)
          
          echo "üìä Response Code: $HTTP_CODE"
          echo "üìÑ Response Body: $BODY"
          
          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "‚úÖ Scraper triggered successfully"
            exit 0
          else
            echo "‚ùå Scraper failed with code $HTTP_CODE"
            exit 1
          fi
      
      - name: Report Failure
        if: failure()
        run: |
          echo "‚ö†Ô∏è Scraper failed!"
          echo "üîç Check Railway logs: https://railway.app/project/your-project/deployments"
          echo "üìß Consider setting up alerts for production"