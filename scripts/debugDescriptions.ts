import { scrapeGreenhouse } from '../lib/scrapers/ats/greenhouse'
import { upsertJobsForCompanyFromAts } from '../lib/jobs/ingestFromAts'
import { prisma } from '../lib/prisma'

async function debug() {
  console.log('\nðŸ” DEBUGGING DESCRIPTION FLOW...\n')
  
  // 1. Get Anthropic company
  const company = await prisma.company.findFirst({
    where: { slug: 'anthropic' }
  })
  
  if (!company) {
    console.log('âŒ Anthropic not found')
    return
  }
  
  console.log('âœ… Found company:', company.name)
  console.log('ATS URL:', company.atsUrl)
  
  // 2. Scrape raw jobs
  console.log('\nðŸ“¥ Scraping jobs...')
  const jobs = await scrapeGreenhouse(company.atsUrl!)
  
  if (jobs.length === 0) {
    console.log('âŒ No jobs scraped')
    return
  }
  
  const job = jobs[0]
  console.log('\nðŸ“‹ First job scraped:')
  console.log('Title:', job.title)
  console.log('Has raw?', !!job.raw)
  console.log('Raw content length:', (job.raw as any)?.content?.length || 0)
  
  // 3. Ingest (this should save to DB)
  console.log('\nðŸ’¾ Ingesting job...')
  await upsertJobsForCompanyFromAts(company, jobs.slice(0, 1))
  
  // 4. Check DB
  console.log('\nðŸ” Checking DB...')
  const dbJob = await prisma.job.findFirst({
    where: {
      title: job.title,
      companyId: company.id
    }
  })
  
  if (dbJob) {
    console.log('âœ… Job in DB')
    console.log('descriptionHtml length:', dbJob.descriptionHtml?.length || 0)
    
    if (!dbJob.descriptionHtml) {
      console.log('\nâŒ DESCRIPTION WAS LOST IN PIPELINE!')
    } else {
      console.log('\nâœ… DESCRIPTION SAVED!')
      console.log('First 200 chars:', dbJob.descriptionHtml.substring(0, 200))
    }
  } else {
    console.log('âŒ Job not found in DB')
  }
}

debug()
  .catch(console.error)
  .finally(() => prisma.$disconnect())
